{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Intro.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "K2xhmpA5BdT3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip3 install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bjzAQBjBiZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.tensor(([2, 9], [1, 5], [3, 6]), dtype=torch.float) # 3 X 2 tensor\n",
        "y = torch.tensor(([92], [100], [89]), dtype=torch.float) # 3 X 1 tensor\n",
        "xPredicted = torch.tensor(([4, 8]), dtype=torch.float) # 1 X 2 tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IfGuYTeCBibG",
        "colab_type": "code",
        "outputId": "948c080f-facd-45c8-ed74-97c5b4381db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(X.size())\n",
        "print(y.size())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "torch.Size([3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3mpTOTReBidN",
        "colab_type": "code",
        "outputId": "f1d5110e-c192-4b6d-ff44-9e688ccddcf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "#Scaling\n",
        "\n",
        "X_max, _ = torch.max(X, 0)\n",
        "xPredicted_max, _ = torch.max(xPredicted, 0)\n",
        "print(X_max)\n",
        "print(_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1.])\n",
            "tensor(1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GQeyxyNcCOkq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bs7fx3g5BifO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = torch.div(X, X_max)\n",
        "xPredicted = torch.div(xPredicted, xPredicted_max)\n",
        "y = y / 100  # max test score is 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TLV-gKkPBihl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Neural_Network(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(Neural_Network, self).__init__()\n",
        "        # parameters\n",
        "        # TODO: parameters can be parameterized instead of declaring them here\n",
        "        self.inputSize = 2\n",
        "        self.outputSize = 1\n",
        "        self.hiddenSize = 3\n",
        "        \n",
        "        # weights\n",
        "        self.W1 = torch.randn(self.inputSize, self.hiddenSize) # 3 X 2 tensor\n",
        "        self.W2 = torch.randn(self.hiddenSize, self.outputSize) # 3 X 1 tensor\n",
        "        \n",
        "    def forward(self, X):\n",
        "        self.z = torch.matmul(X, self.W1) # 3 X 3 \".dot\" does not broadcast in PyTorch\n",
        "        self.z2 = self.sigmoid(self.z) # activation function\n",
        "        self.z3 = torch.matmul(self.z2, self.W2)\n",
        "        o = self.sigmoid(self.z3) # final activation function\n",
        "        return o\n",
        "        \n",
        "    def sigmoid(self, s):\n",
        "        return 1 / (1 + torch.exp(-s))\n",
        "    def sigmoidPrime(self, s):\n",
        "        # derivative of sigmoid\n",
        "        return s * (1 - s)\n",
        "    def backward(self, X, y, o):\n",
        "        self.o_error = y - o # error in output\n",
        "        self.o_delta = self.o_error * self.sigmoidPrime(o) # derivative of sig to error\n",
        "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
        "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
        "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
        "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
        "        \n",
        "    def train(self, X, y):\n",
        "        # forward + backward pass for training\n",
        "        o = self.forward(X)\n",
        "        self.backward(X, y, o)\n",
        "        \n",
        "    def saveWeights(self, model):\n",
        "        # we will use the PyTorch internal storage functions\n",
        "        torch.save(model, \"NN\")\n",
        "        # you can reload model with all the weights and so forth with:\n",
        "        # torch.load(\"NN\")\n",
        "        \n",
        "    def predict(self):\n",
        "        print (\"Predicted data based on trained weights: \")\n",
        "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
        "        print (\"Output: \\n\" + str(self.forward(xPredicted)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TshEF7YvBik0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16954
        },
        "outputId": "682b90d4-3977-4067-d05a-e9dd3b37a87d"
      },
      "cell_type": "code",
      "source": [
        "NN = Neural_Network()\n",
        "for i in range(1000):  # trains the NN 1,000 times\n",
        "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
        "    NN.train(X, y)\n",
        "NN.saveWeights(NN)\n",
        "NN.predict()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#0 Loss: 0.506162166595459\n",
            "#1 Loss: 0.4290335178375244\n",
            "#2 Loss: 0.35330602526664734\n",
            "#3 Loss: 0.2862093448638916\n",
            "#4 Loss: 0.23054403066635132\n",
            "#5 Loss: 0.18560270965099335\n",
            "#6 Loss: 0.14952759444713593\n",
            "#7 Loss: 0.12059015780687332\n",
            "#8 Loss: 0.09745504707098007\n",
            "#9 Loss: 0.07907887548208237\n",
            "#10 Loss: 0.06458688527345657\n",
            "#11 Loss: 0.053216353058815\n",
            "#12 Loss: 0.04430847242474556\n",
            "#13 Loss: 0.03731384500861168\n",
            "#14 Loss: 0.031791362911462784\n",
            "#15 Loss: 0.02739730477333069\n",
            "#16 Loss: 0.023869121447205544\n",
            "#17 Loss: 0.02100847102701664\n",
            "#18 Loss: 0.018666014075279236\n",
            "#19 Loss: 0.01672924868762493\n",
            "#20 Loss: 0.015112980268895626\n",
            "#21 Loss: 0.013752293772995472\n",
            "#22 Loss: 0.012597314082086086\n",
            "#23 Loss: 0.011609395034611225\n",
            "#24 Loss: 0.01075836643576622\n",
            "#25 Loss: 0.01002038735896349\n",
            "#26 Loss: 0.00937651563435793\n",
            "#27 Loss: 0.008811580017209053\n",
            "#28 Loss: 0.00831326749175787\n",
            "#29 Loss: 0.007871582172811031\n",
            "#30 Loss: 0.0074783130548894405\n",
            "#31 Loss: 0.007126671727746725\n",
            "#32 Loss: 0.00681101530790329\n",
            "#33 Loss: 0.006526617798954248\n",
            "#34 Loss: 0.006269486155360937\n",
            "#35 Loss: 0.006036276463419199\n",
            "#36 Loss: 0.005824105814099312\n",
            "#37 Loss: 0.005630549509078264\n",
            "#38 Loss: 0.00545348459854722\n",
            "#39 Loss: 0.005291090812534094\n",
            "#40 Loss: 0.005141813308000565\n",
            "#41 Loss: 0.005004275124520063\n",
            "#42 Loss: 0.004877293016761541\n",
            "#43 Loss: 0.004759796429425478\n",
            "#44 Loss: 0.0046508884988725185\n",
            "#45 Loss: 0.0045497482642531395\n",
            "#46 Loss: 0.004455663729459047\n",
            "#47 Loss: 0.0043679880909621716\n",
            "#48 Loss: 0.004286167677491903\n",
            "#49 Loss: 0.004209685139358044\n",
            "#50 Loss: 0.0041380892507731915\n",
            "#51 Loss: 0.004070976749062538\n",
            "#52 Loss: 0.004007980227470398\n",
            "#53 Loss: 0.003948776982724667\n",
            "#54 Loss: 0.003893063170835376\n",
            "#55 Loss: 0.003840582212433219\n",
            "#56 Loss: 0.00379108265042305\n",
            "#57 Loss: 0.003744337009266019\n",
            "#58 Loss: 0.0037001539021730423\n",
            "#59 Loss: 0.003658355912193656\n",
            "#60 Loss: 0.003618759335950017\n",
            "#61 Loss: 0.003581220982596278\n",
            "#62 Loss: 0.0035456030163913965\n",
            "#63 Loss: 0.0035117764491587877\n",
            "#64 Loss: 0.003479618579149246\n",
            "#65 Loss: 0.003449019743129611\n",
            "#66 Loss: 0.0034198893699795008\n",
            "#67 Loss: 0.003392124781385064\n",
            "#68 Loss: 0.0033656463492661715\n",
            "#69 Loss: 0.003340374445542693\n",
            "#70 Loss: 0.0033162415493279696\n",
            "#71 Loss: 0.00329316477291286\n",
            "#72 Loss: 0.0032710926607251167\n",
            "#73 Loss: 0.003249972825869918\n",
            "#74 Loss: 0.003229741007089615\n",
            "#75 Loss: 0.003210346447303891\n",
            "#76 Loss: 0.003191746771335602\n",
            "#77 Loss: 0.0031738963443785906\n",
            "#78 Loss: 0.003156751161441207\n",
            "#79 Loss: 0.00314028630964458\n",
            "#80 Loss: 0.003124450333416462\n",
            "#81 Loss: 0.0031092234421521425\n",
            "#82 Loss: 0.0030945520848035812\n",
            "#83 Loss: 0.003080431604757905\n",
            "#84 Loss: 0.003066825680434704\n",
            "#85 Loss: 0.0030536979902535677\n",
            "#86 Loss: 0.0030410417821258307\n",
            "#87 Loss: 0.0030288209673017263\n",
            "#88 Loss: 0.0030170197132974863\n",
            "#89 Loss: 0.003005622886121273\n",
            "#90 Loss: 0.002994601847603917\n",
            "#91 Loss: 0.002983936108648777\n",
            "#92 Loss: 0.002973625436425209\n",
            "#93 Loss: 0.002963633043691516\n",
            "#94 Loss: 0.002953956602141261\n",
            "#95 Loss: 0.0029445805121213198\n",
            "#96 Loss: 0.002935487776994705\n",
            "#97 Loss: 0.002926672575995326\n",
            "#98 Loss: 0.0029181099962443113\n",
            "#99 Loss: 0.0029097956139594316\n",
            "#100 Loss: 0.002901723375543952\n",
            "#101 Loss: 0.0028938772156834602\n",
            "#102 Loss: 0.002886251313611865\n",
            "#103 Loss: 0.0028788310009986162\n",
            "#104 Loss: 0.002871609292924404\n",
            "#105 Loss: 0.002864579437300563\n",
            "#106 Loss: 0.002857733750715852\n",
            "#107 Loss: 0.0028510650154203176\n",
            "#108 Loss: 0.0028445597272366285\n",
            "#109 Loss: 0.0028382232412695885\n",
            "#110 Loss: 0.0028320334386080503\n",
            "#111 Loss: 0.0028259912505745888\n",
            "#112 Loss: 0.0028200987726449966\n",
            "#113 Loss: 0.002814337844029069\n",
            "#114 Loss: 0.002808714285492897\n",
            "#115 Loss: 0.0028032066766172647\n",
            "#116 Loss: 0.0027978308498859406\n",
            "#117 Loss: 0.002792567014694214\n",
            "#118 Loss: 0.002787418430671096\n",
            "#119 Loss: 0.002782374620437622\n",
            "#120 Loss: 0.0027774283662438393\n",
            "#121 Loss: 0.002772592008113861\n",
            "#122 Loss: 0.0027678499463945627\n",
            "#123 Loss: 0.0027631937991827726\n",
            "#124 Loss: 0.00275863497518003\n",
            "#125 Loss: 0.0027541571762412786\n",
            "#126 Loss: 0.002749760402366519\n",
            "#127 Loss: 0.002745445119217038\n",
            "#128 Loss: 0.002741207368671894\n",
            "#129 Loss: 0.00273704226128757\n",
            "#130 Loss: 0.002732948400080204\n",
            "#131 Loss: 0.0027289167046546936\n",
            "#132 Loss: 0.002724955091252923\n",
            "#133 Loss: 0.002721060998737812\n",
            "#134 Loss: 0.002717227442190051\n",
            "#135 Loss: 0.002713451161980629\n",
            "#136 Loss: 0.0027097342535853386\n",
            "#137 Loss: 0.0027060683351010084\n",
            "#138 Loss: 0.002702454337850213\n",
            "#139 Loss: 0.0026988936588168144\n",
            "#140 Loss: 0.0026953883934766054\n",
            "#141 Loss: 0.0026919282972812653\n",
            "#142 Loss: 0.002688506618142128\n",
            "#143 Loss: 0.0026851408183574677\n",
            "#144 Loss: 0.0026818106416612864\n",
            "#145 Loss: 0.002678520046174526\n",
            "#146 Loss: 0.002675275318324566\n",
            "#147 Loss: 0.002672063885256648\n",
            "#148 Loss: 0.002668897621333599\n",
            "#149 Loss: 0.002665758365765214\n",
            "#150 Loss: 0.0026626605540513992\n",
            "#151 Loss: 0.00265959813259542\n",
            "#152 Loss: 0.0026565587613731623\n",
            "#153 Loss: 0.0026535606011748314\n",
            "#154 Loss: 0.00265059364028275\n",
            "#155 Loss: 0.002647652290761471\n",
            "#156 Loss: 0.00264473888091743\n",
            "#157 Loss: 0.002641853876411915\n",
            "#158 Loss: 0.002638992154970765\n",
            "#159 Loss: 0.0026361632626503706\n",
            "#160 Loss: 0.002633353928104043\n",
            "#161 Loss: 0.0026305709034204483\n",
            "#162 Loss: 0.002627805108204484\n",
            "#163 Loss: 0.0026250712107867002\n",
            "#164 Loss: 0.0026223554741591215\n",
            "#165 Loss: 0.002619657665491104\n",
            "#166 Loss: 0.0026169868651777506\n",
            "#167 Loss: 0.002614331664517522\n",
            "#168 Loss: 0.0026116964872926474\n",
            "#169 Loss: 0.0026090743485838175\n",
            "#170 Loss: 0.0026064759586006403\n",
            "#171 Loss: 0.0026039008516818285\n",
            "#172 Loss: 0.002601331565529108\n",
            "#173 Loss: 0.002598782069981098\n",
            "#174 Loss: 0.002596249571070075\n",
            "#175 Loss: 0.002593731740489602\n",
            "#176 Loss: 0.002591230208054185\n",
            "#177 Loss: 0.0025887356605380774\n",
            "#178 Loss: 0.002586259739473462\n",
            "#179 Loss: 0.00258380058221519\n",
            "#180 Loss: 0.0025813530664891005\n",
            "#181 Loss: 0.0025789139326661825\n",
            "#182 Loss: 0.002576488070189953\n",
            "#183 Loss: 0.002574074314907193\n",
            "#184 Loss: 0.0025716766249388456\n",
            "#185 Loss: 0.0025692814961075783\n",
            "#186 Loss: 0.002566904528066516\n",
            "#187 Loss: 0.002564531983807683\n",
            "#188 Loss: 0.0025621720124036074\n",
            "#189 Loss: 0.002559818560257554\n",
            "#190 Loss: 0.002557477680966258\n",
            "#191 Loss: 0.0025551498401910067\n",
            "#192 Loss: 0.0025528217665851116\n",
            "#193 Loss: 0.002550506731495261\n",
            "#194 Loss: 0.0025481965858489275\n",
            "#195 Loss: 0.0025459027383476496\n",
            "#196 Loss: 0.0025436109863221645\n",
            "#197 Loss: 0.0025413224939256907\n",
            "#198 Loss: 0.002539044711738825\n",
            "#199 Loss: 0.0025367725174874067\n",
            "#200 Loss: 0.002534513594582677\n",
            "#201 Loss: 0.0025322549045085907\n",
            "#202 Loss: 0.002530004596337676\n",
            "#203 Loss: 0.0025277535896748304\n",
            "#204 Loss: 0.0025255156215280294\n",
            "#205 Loss: 0.002523277886211872\n",
            "#206 Loss: 0.0025210510939359665\n",
            "#207 Loss: 0.0025188305880874395\n",
            "#208 Loss: 0.0025166096165776253\n",
            "#209 Loss: 0.002514391904696822\n",
            "#210 Loss: 0.002512183738872409\n",
            "#211 Loss: 0.0025099802296608686\n",
            "#212 Loss: 0.0025077825412154198\n",
            "#213 Loss: 0.0025055864825844765\n",
            "#214 Loss: 0.0025033929850906134\n",
            "#215 Loss: 0.0025012092664837837\n",
            "#216 Loss: 0.002499018330127001\n",
            "#217 Loss: 0.002496838103979826\n",
            "#218 Loss: 0.002494666026905179\n",
            "#219 Loss: 0.002492485800758004\n",
            "#220 Loss: 0.0024903162848204374\n",
            "#221 Loss: 0.0024881535209715366\n",
            "#222 Loss: 0.0024859842378646135\n",
            "#223 Loss: 0.0024838268291205168\n",
            "#224 Loss: 0.00248166685923934\n",
            "#225 Loss: 0.0024795110803097486\n",
            "#226 Loss: 0.0024773585610091686\n",
            "#227 Loss: 0.002475204411894083\n",
            "#228 Loss: 0.0024730560835450888\n",
            "#229 Loss: 0.0024709152057766914\n",
            "#230 Loss: 0.0024687654804438353\n",
            "#231 Loss: 0.002466624602675438\n",
            "#232 Loss: 0.0024644900113344193\n",
            "#233 Loss: 0.0024623500648885965\n",
            "#234 Loss: 0.0024602143093943596\n",
            "#235 Loss: 0.0024580785539001226\n",
            "#236 Loss: 0.0024559451267123222\n",
            "#237 Loss: 0.0024538200814276934\n",
            "#238 Loss: 0.002451687352731824\n",
            "#239 Loss: 0.002449559746310115\n",
            "#240 Loss: 0.0024474328383803368\n",
            "#241 Loss: 0.0024453105870634317\n",
            "#242 Loss: 0.0024431897327303886\n",
            "#243 Loss: 0.0024410702753812075\n",
            "#244 Loss: 0.0024389447644352913\n",
            "#245 Loss: 0.0024368236772716045\n",
            "#246 Loss: 0.0024347074795514345\n",
            "#247 Loss: 0.00243259035050869\n",
            "#248 Loss: 0.002430473454296589\n",
            "#249 Loss: 0.0024283556267619133\n",
            "#250 Loss: 0.0024262459482997656\n",
            "#251 Loss: 0.0024241304490715265\n",
            "#252 Loss: 0.0024220149498432875\n",
            "#253 Loss: 0.002419904572889209\n",
            "#254 Loss: 0.002417795592918992\n",
            "#255 Loss: 0.0024156856816262007\n",
            "#256 Loss: 0.002413575304672122\n",
            "#257 Loss: 0.002411469118669629\n",
            "#258 Loss: 0.002409358276054263\n",
            "#259 Loss: 0.00240725209005177\n",
            "#260 Loss: 0.0024051410146057606\n",
            "#261 Loss: 0.002403033897280693\n",
            "#262 Loss: 0.002400928409770131\n",
            "#263 Loss: 0.0023988254833966494\n",
            "#264 Loss: 0.0023967195302248\n",
            "#265 Loss: 0.0023946103174239397\n",
            "#266 Loss: 0.002392503200098872\n",
            "#267 Loss: 0.0023904063273221254\n",
            "#268 Loss: 0.0023882996756583452\n",
            "#269 Loss: 0.002386195817962289\n",
            "#270 Loss: 0.002384093590080738\n",
            "#271 Loss: 0.002381988801062107\n",
            "#272 Loss: 0.002379887504503131\n",
            "#273 Loss: 0.0023777817841619253\n",
            "#274 Loss: 0.00237568118609488\n",
            "#275 Loss: 0.002373573835939169\n",
            "#276 Loss: 0.002371475799009204\n",
            "#277 Loss: 0.002369371009990573\n",
            "#278 Loss: 0.0023672720417380333\n",
            "#279 Loss: 0.0023651651572436094\n",
            "#280 Loss: 0.002363065956160426\n",
            "#281 Loss: 0.0023609620984643698\n",
            "#282 Loss: 0.002358862431719899\n",
            "#283 Loss: 0.002356761135160923\n",
            "#284 Loss: 0.002354656346142292\n",
            "#285 Loss: 0.0023525541182607412\n",
            "#286 Loss: 0.0023504525888711214\n",
            "#287 Loss: 0.002348353387787938\n",
            "#288 Loss: 0.0023462509270757437\n",
            "#289 Loss: 0.002344148699194193\n",
            "#290 Loss: 0.0023420483339577913\n",
            "#291 Loss: 0.002339943079277873\n",
            "#292 Loss: 0.0023378413170576096\n",
            "#293 Loss: 0.0023357386235147715\n",
            "#294 Loss: 0.0023336338344961405\n",
            "#295 Loss: 0.002331532770767808\n",
            "#296 Loss: 0.0023294263519346714\n",
            "#297 Loss: 0.0023273304104804993\n",
            "#298 Loss: 0.0023252281825989485\n",
            "#299 Loss: 0.0023231287486851215\n",
            "#300 Loss: 0.002321019070222974\n",
            "#301 Loss: 0.002318916143849492\n",
            "#302 Loss: 0.002316812053322792\n",
            "#303 Loss: 0.0023147116880863905\n",
            "#304 Loss: 0.0023126087617129087\n",
            "#305 Loss: 0.0023105021100491285\n",
            "#306 Loss: 0.0023083994165062904\n",
            "#307 Loss: 0.0023062978871166706\n",
            "#308 Loss: 0.0023041937965899706\n",
            "#309 Loss: 0.0023020945955067873\n",
            "#310 Loss: 0.0022999898064881563\n",
            "#311 Loss: 0.0022978843189775944\n",
            "#312 Loss: 0.002295779762789607\n",
            "#313 Loss: 0.0022936786990612745\n",
            "#314 Loss: 0.0022915678564459085\n",
            "#315 Loss: 0.002289464697241783\n",
            "#316 Loss: 0.0022873624693602324\n",
            "#317 Loss: 0.0022852590773254633\n",
            "#318 Loss: 0.0022831528913229704\n",
            "#319 Loss: 0.002281049033626914\n",
            "#320 Loss: 0.002278944244608283\n",
            "#321 Loss: 0.002276844112202525\n",
            "#322 Loss: 0.002274734666571021\n",
            "#323 Loss: 0.0022726324386894703\n",
            "#324 Loss: 0.0022705255541950464\n",
            "#325 Loss: 0.00226842169649899\n",
            "#326 Loss: 0.0022663134150207043\n",
            "#327 Loss: 0.0022642093244940042\n",
            "#328 Loss: 0.0022621036041527987\n",
            "#329 Loss: 0.0022599990479648113\n",
            "#330 Loss: 0.0022578928619623184\n",
            "#331 Loss: 0.0022557855118066072\n",
            "#332 Loss: 0.0022536811884492636\n",
            "#333 Loss: 0.002251573372632265\n",
            "#334 Loss: 0.0022494662553071976\n",
            "#335 Loss: 0.0022473670542240143\n",
            "#336 Loss: 0.0022452569101005793\n",
            "#337 Loss: 0.002243151655420661\n",
            "#338 Loss: 0.0022410470992326736\n",
            "#339 Loss: 0.0022389444056898355\n",
            "#340 Loss: 0.0022368368227034807\n",
            "#341 Loss: 0.0022347336634993553\n",
            "#342 Loss: 0.002232624450698495\n",
            "#343 Loss: 0.002230521524325013\n",
            "#344 Loss: 0.00222841277718544\n",
            "#345 Loss: 0.0022263082209974527\n",
            "#346 Loss: 0.0022242076229304075\n",
            "#347 Loss: 0.0022220986429601908\n",
            "#348 Loss: 0.0022199952509254217\n",
            "#349 Loss: 0.0022178899962455034\n",
            "#350 Loss: 0.0022157863713800907\n",
            "#351 Loss: 0.002213678089901805\n",
            "#352 Loss: 0.0022115737665444613\n",
            "#353 Loss: 0.0022094666492193937\n",
            "#354 Loss: 0.0022073667496442795\n",
            "#355 Loss: 0.0022052612621337175\n",
            "#356 Loss: 0.0022031592670828104\n",
            "#357 Loss: 0.0022010523825883865\n",
            "#358 Loss: 0.002198952017351985\n",
            "#359 Loss: 0.0021968460641801357\n",
            "#360 Loss: 0.0021947429049760103\n",
            "#361 Loss: 0.0021926392801105976\n",
            "#362 Loss: 0.002190534258261323\n",
            "#363 Loss: 0.0021884357556700706\n",
            "#364 Loss: 0.002186327474191785\n",
            "#365 Loss: 0.0021842254791408777\n",
            "#366 Loss: 0.002182123251259327\n",
            "#367 Loss: 0.002180020557716489\n",
            "#368 Loss: 0.0021779241506010294\n",
            "#369 Loss: 0.002175820292904973\n",
            "#370 Loss: 0.0021737224888056517\n",
            "#371 Loss: 0.002171618863940239\n",
            "#372 Loss: 0.002169518731534481\n",
            "#373 Loss: 0.0021674211602658033\n",
            "#374 Loss: 0.0021653196308761835\n",
            "#375 Loss: 0.0021632162388414145\n",
            "#376 Loss: 0.0021611216943711042\n",
            "#377 Loss: 0.002159022493287921\n",
            "#378 Loss: 0.002156924456357956\n",
            "#379 Loss: 0.0021548287477344275\n",
            "#380 Loss: 0.0021527267526835203\n",
            "#381 Loss: 0.0021506294142454863\n",
            "#382 Loss: 0.0021485339384526014\n",
            "#383 Loss: 0.002146436832845211\n",
            "#384 Loss: 0.0021443406585603952\n",
            "#385 Loss: 0.002142244717106223\n",
            "#386 Loss: 0.0021401504054665565\n",
            "#387 Loss: 0.0021380551625043154\n",
            "#388 Loss: 0.0021359578240662813\n",
            "#389 Loss: 0.0021338695660233498\n",
            "#390 Loss: 0.0021317729260772467\n",
            "#391 Loss: 0.0021296790800988674\n",
            "#392 Loss: 0.0021275922190397978\n",
            "#393 Loss: 0.002125498140230775\n",
            "#394 Loss: 0.002123406855389476\n",
            "#395 Loss: 0.0021213169675320387\n",
            "#396 Loss: 0.002119228010997176\n",
            "#397 Loss: 0.0021171404514461756\n",
            "#398 Loss: 0.0021150449756532907\n",
            "#399 Loss: 0.002112960210070014\n",
            "#400 Loss: 0.0021108712535351515\n",
            "#401 Loss: 0.0021087864879518747\n",
            "#402 Loss: 0.002106699161231518\n",
            "#403 Loss: 0.0021046155598014593\n",
            "#404 Loss: 0.0021025282330811024\n",
            "#405 Loss: 0.0021004413720220327\n",
            "#406 Loss: 0.0020983589347451925\n",
            "#407 Loss: 0.0020962755661457777\n",
            "#408 Loss: 0.0020941945258527994\n",
            "#409 Loss: 0.0020921153482049704\n",
            "#410 Loss: 0.002090029651299119\n",
            "#411 Loss: 0.0020879500079900026\n",
            "#412 Loss: 0.002085872692987323\n",
            "#413 Loss: 0.0020837897900491953\n",
            "#414 Loss: 0.002081717364490032\n",
            "#415 Loss: 0.002079635625705123\n",
            "#416 Loss: 0.0020775615703314543\n",
            "#417 Loss: 0.002075487980619073\n",
            "#418 Loss: 0.002073410665616393\n",
            "#419 Loss: 0.0020713366102427244\n",
            "#420 Loss: 0.0020692606922239065\n",
            "#421 Loss: 0.002067186404019594\n",
            "#422 Loss: 0.0020651184022426605\n",
            "#423 Loss: 0.0020630492363125086\n",
            "#424 Loss: 0.0020609782077372074\n",
            "#425 Loss: 0.0020589090418070555\n",
            "#426 Loss: 0.002056840341538191\n",
            "#427 Loss: 0.0020547739695757627\n",
            "#428 Loss: 0.002052705967798829\n",
            "#429 Loss: 0.002050641691312194\n",
            "#430 Loss: 0.0020485769491642714\n",
            "#431 Loss: 0.0020465166307985783\n",
            "#432 Loss: 0.0020444528199732304\n",
            "#433 Loss: 0.0020423883106559515\n",
            "#434 Loss: 0.002040331484749913\n",
            "#435 Loss: 0.0020382695365697145\n",
            "#436 Loss: 0.002036212245002389\n",
            "#437 Loss: 0.002034158445894718\n",
            "#438 Loss: 0.0020320957992225885\n",
            "#439 Loss: 0.002030044561251998\n",
            "#440 Loss: 0.002027988899499178\n",
            "#441 Loss: 0.002025933237746358\n",
            "#442 Loss: 0.002023879671469331\n",
            "#443 Loss: 0.00202182843349874\n",
            "#444 Loss: 0.002019780222326517\n",
            "#445 Loss: 0.0020177338737994432\n",
            "#446 Loss: 0.002015684498474002\n",
            "#447 Loss: 0.0020136365201324224\n",
            "#448 Loss: 0.0020115887746214867\n",
            "#449 Loss: 0.002009546384215355\n",
            "#450 Loss: 0.0020075005013495684\n",
            "#451 Loss: 0.002005458576604724\n",
            "#452 Loss: 0.0020034166518598795\n",
            "#453 Loss: 0.0020013824105262756\n",
            "#454 Loss: 0.0019993355963379145\n",
            "#455 Loss: 0.001997303916141391\n",
            "#456 Loss: 0.0019952666480094194\n",
            "#457 Loss: 0.001993232173845172\n",
            "#458 Loss: 0.001991195837035775\n",
            "#459 Loss: 0.0019891667179763317\n",
            "#460 Loss: 0.0019871320109814405\n",
            "#461 Loss: 0.001985101727768779\n",
            "#462 Loss: 0.0019830733072012663\n",
            "#463 Loss: 0.001981049543246627\n",
            "#464 Loss: 0.0019790201913565397\n",
            "#465 Loss: 0.001976992003619671\n",
            "#466 Loss: 0.001974973129108548\n",
            "#467 Loss: 0.0019729482010006905\n",
            "#468 Loss: 0.001970926532521844\n",
            "#469 Loss: 0.0019689055625349283\n",
            "#470 Loss: 0.0019668908789753914\n",
            "#471 Loss: 0.001964871073141694\n",
            "#472 Loss: 0.0019628575537353754\n",
            "#473 Loss: 0.001960843103006482\n",
            "#474 Loss: 0.001958830514922738\n",
            "#475 Loss: 0.0019568202551454306\n",
            "#476 Loss: 0.0019548083655536175\n",
            "#477 Loss: 0.0019528005504980683\n",
            "#478 Loss: 0.0019507920369505882\n",
            "#479 Loss: 0.0019487914396449924\n",
            "#480 Loss: 0.0019467828096821904\n",
            "#481 Loss: 0.0019447795348241925\n",
            "#482 Loss: 0.0019427761435508728\n",
            "#483 Loss: 0.0019407793879508972\n",
            "#484 Loss: 0.0019387779757380486\n",
            "#485 Loss: 0.0019367829663679004\n",
            "#486 Loss: 0.0019347881898283958\n",
            "#487 Loss: 0.0019327900372445583\n",
            "#488 Loss: 0.0019308015471324325\n",
            "#489 Loss: 0.0019288072362542152\n",
            "#490 Loss: 0.0019268222386017442\n",
            "#491 Loss: 0.0019248351454734802\n",
            "#492 Loss: 0.0019228464225307107\n",
            "#493 Loss: 0.0019208639860153198\n",
            "#494 Loss: 0.0019188807345926762\n",
            "#495 Loss: 0.0019168966682627797\n",
            "#496 Loss: 0.0019149171421304345\n",
            "#497 Loss: 0.0019129404099658132\n",
            "#498 Loss: 0.001910960883833468\n",
            "#499 Loss: 0.001908987876959145\n",
            "#500 Loss: 0.0019070148700848222\n",
            "#501 Loss: 0.0019050416303798556\n",
            "#502 Loss: 0.001903066411614418\n",
            "#503 Loss: 0.0019011031836271286\n",
            "#504 Loss: 0.0018991330871358514\n",
            "#505 Loss: 0.0018971702083945274\n",
            "#506 Loss: 0.0018952052341774106\n",
            "#507 Loss: 0.0018932423554360867\n",
            "#508 Loss: 0.0018912825034931302\n",
            "#509 Loss: 0.0018893260275945067\n",
            "#510 Loss: 0.001887367106974125\n",
            "#511 Loss: 0.0018854117952287197\n",
            "#512 Loss: 0.0018834583461284637\n",
            "#513 Loss: 0.0018815086223185062\n",
            "#514 Loss: 0.0018795564537867904\n",
            "#515 Loss: 0.0018776128999888897\n",
            "#516 Loss: 0.0018756616627797484\n",
            "#517 Loss: 0.0018737207865342498\n",
            "#518 Loss: 0.0018717794446274638\n",
            "#519 Loss: 0.001869835308752954\n",
            "#520 Loss: 0.0018678972264751792\n",
            "#521 Loss: 0.0018659546039998531\n",
            "#522 Loss: 0.0018640202470123768\n",
            "#523 Loss: 0.0018620864721015096\n",
            "#524 Loss: 0.0018601560732349753\n",
            "#525 Loss: 0.0018582249758765101\n",
            "#526 Loss: 0.00185629993211478\n",
            "#527 Loss: 0.0018543672049418092\n",
            "#528 Loss: 0.0018524453043937683\n",
            "#529 Loss: 0.0018505221232771873\n",
            "#530 Loss: 0.0018486035987734795\n",
            "#531 Loss: 0.0018466805340722203\n",
            "#532 Loss: 0.0018447645707055926\n",
            "#533 Loss: 0.0018428495386615396\n",
            "#534 Loss: 0.0018409356707707047\n",
            "#535 Loss: 0.0018390231998637319\n",
            "#536 Loss: 0.001837115385569632\n",
            "#537 Loss: 0.0018352019833400846\n",
            "#538 Loss: 0.0018332957988604903\n",
            "#539 Loss: 0.0018313942709937692\n",
            "#540 Loss: 0.0018294936744496226\n",
            "#541 Loss: 0.0018275907495990396\n",
            "#542 Loss: 0.0018256934126839042\n",
            "#543 Loss: 0.0018238011980429292\n",
            "#544 Loss: 0.0018219024641439319\n",
            "#545 Loss: 0.0018200097838416696\n",
            "#546 Loss: 0.0018181190825998783\n",
            "#547 Loss: 0.0018162321066483855\n",
            "#548 Loss: 0.0018143419874832034\n",
            "#549 Loss: 0.0018124604830518365\n",
            "#550 Loss: 0.0018105776980519295\n",
            "#551 Loss: 0.0018086970085278153\n",
            "#552 Loss: 0.0018068169010803103\n",
            "#553 Loss: 0.0018049433128908277\n",
            "#554 Loss: 0.0018030684441328049\n",
            "#555 Loss: 0.001801192294806242\n",
            "#556 Loss: 0.0017993237124755979\n",
            "#557 Loss: 0.001797451637685299\n",
            "#558 Loss: 0.001795584219507873\n",
            "#559 Loss: 0.0017937254160642624\n",
            "#560 Loss: 0.0017918605590239167\n",
            "#561 Loss: 0.0017900002421811223\n",
            "#562 Loss: 0.001788141205906868\n",
            "#563 Loss: 0.0017862858949229121\n",
            "#564 Loss: 0.0017844326794147491\n",
            "#565 Loss: 0.001782578299753368\n",
            "#566 Loss: 0.0017807286931201816\n",
            "#567 Loss: 0.0017788816476240754\n",
            "#568 Loss: 0.0017770343692973256\n",
            "#569 Loss: 0.0017751926789060235\n",
            "#570 Loss: 0.0017733507556840777\n",
            "#571 Loss: 0.001771509530954063\n",
            "#572 Loss: 0.0017696720315143466\n",
            "#573 Loss: 0.0017678370932117105\n",
            "#574 Loss: 0.0017660037847235799\n",
            "#575 Loss: 0.0017641731537878513\n",
            "#576 Loss: 0.0017623432213440537\n",
            "#577 Loss: 0.001760516781359911\n",
            "#578 Loss: 0.00175869045779109\n",
            "#579 Loss: 0.0017568693729117513\n",
            "#580 Loss: 0.0017550477059558034\n",
            "#581 Loss: 0.001753227785229683\n",
            "#582 Loss: 0.001751413568854332\n",
            "#583 Loss: 0.0017495994688943028\n",
            "#584 Loss: 0.0017477875808253884\n",
            "#585 Loss: 0.001745977788232267\n",
            "#586 Loss: 0.0017441726522520185\n",
            "#587 Loss: 0.0017423639073967934\n",
            "#588 Loss: 0.0017405655235052109\n",
            "#589 Loss: 0.0017387625994160771\n",
            "#590 Loss: 0.0017369585111737251\n",
            "#591 Loss: 0.0017351635033264756\n",
            "#592 Loss: 0.0017333695432171226\n",
            "#593 Loss: 0.0017315760487690568\n",
            "#594 Loss: 0.0017297882586717606\n",
            "#595 Loss: 0.0017279997700825334\n",
            "#596 Loss: 0.0017262175679206848\n",
            "#597 Loss: 0.0017244300106540322\n",
            "#598 Loss: 0.0017226486233994365\n",
            "#599 Loss: 0.0017208707286044955\n",
            "#600 Loss: 0.0017190963262692094\n",
            "#601 Loss: 0.0017173215746879578\n",
            "#602 Loss: 0.001715544261969626\n",
            "#603 Loss: 0.0017137761460617185\n",
            "#604 Loss: 0.001712010707706213\n",
            "#605 Loss: 0.001710244338028133\n",
            "#606 Loss: 0.0017084769206121564\n",
            "#607 Loss: 0.0017067171866074204\n",
            "#608 Loss: 0.0017049582675099373\n",
            "#609 Loss: 0.0017032051691785455\n",
            "#610 Loss: 0.001701450441032648\n",
            "#611 Loss: 0.001699696178548038\n",
            "#612 Loss: 0.001697947853244841\n",
            "#613 Loss: 0.001696202321909368\n",
            "#614 Loss: 0.0016944585368037224\n",
            "#615 Loss: 0.0016927141696214676\n",
            "#616 Loss: 0.0016909706173464656\n",
            "#617 Loss: 0.0016892350977286696\n",
            "#618 Loss: 0.0016874995781108737\n",
            "#619 Loss: 0.0016857610316947103\n",
            "#620 Loss: 0.0016840309835970402\n",
            "#621 Loss: 0.0016823011683300138\n",
            "#622 Loss: 0.0016805768245831132\n",
            "#623 Loss: 0.0016788503853604198\n",
            "#624 Loss: 0.0016771325608715415\n",
            "#625 Loss: 0.0016754098469391465\n",
            "#626 Loss: 0.0016736913239583373\n",
            "#627 Loss: 0.0016719745472073555\n",
            "#628 Loss: 0.0016702632419764996\n",
            "#629 Loss: 0.0016685504233464599\n",
            "#630 Loss: 0.0016668438911437988\n",
            "#631 Loss: 0.0016651347978040576\n",
            "#632 Loss: 0.0016634325729683042\n",
            "#633 Loss: 0.0016617303481325507\n",
            "#634 Loss: 0.0016600302187725902\n",
            "#635 Loss: 0.0016583384713158011\n",
            "#636 Loss: 0.00165664276573807\n",
            "#637 Loss: 0.001654952415265143\n",
            "#638 Loss: 0.0016532581066712737\n",
            "#639 Loss: 0.0016515738097950816\n",
            "#640 Loss: 0.0016498902114108205\n",
            "#641 Loss: 0.0016482042847201228\n",
            "#642 Loss: 0.0016465220833197236\n",
            "#643 Loss: 0.0016448445385321975\n",
            "#644 Loss: 0.0016431669937446713\n",
            "#645 Loss: 0.0016414951533079147\n",
            "#646 Loss: 0.0016398235457018018\n",
            "#647 Loss: 0.0016381553141400218\n",
            "#648 Loss: 0.0016364880139008164\n",
            "#649 Loss: 0.0016348276985809207\n",
            "#650 Loss: 0.0016331634251400828\n",
            "#651 Loss: 0.001631505903787911\n",
            "#652 Loss: 0.0016298488480970263\n",
            "#653 Loss: 0.00162819295655936\n",
            "#654 Loss: 0.0016265390440821648\n",
            "#655 Loss: 0.0016248902538791299\n",
            "#656 Loss: 0.0016232432099059224\n",
            "#657 Loss: 0.001621597446501255\n",
            "#658 Loss: 0.0016199550591409206\n",
            "#659 Loss: 0.0016183165134862065\n",
            "#660 Loss: 0.0016166745917871594\n",
            "#661 Loss: 0.0016150418668985367\n",
            "#662 Loss: 0.0016134065808728337\n",
            "#663 Loss: 0.0016117742052301764\n",
            "#664 Loss: 0.0016101459041237831\n",
            "#665 Loss: 0.001608520862646401\n",
            "#666 Loss: 0.001606895704753697\n",
            "#667 Loss: 0.0016052806749939919\n",
            "#668 Loss: 0.0016036565648391843\n",
            "#669 Loss: 0.0016020400216802955\n",
            "#670 Loss: 0.0016004283679649234\n",
            "#671 Loss: 0.0015988139202818274\n",
            "#672 Loss: 0.0015972070395946503\n",
            "#673 Loss: 0.0015955971321091056\n",
            "#674 Loss: 0.0015939947916194797\n",
            "#675 Loss: 0.0015923896571621299\n",
            "#676 Loss: 0.001590787898749113\n",
            "#677 Loss: 0.001589192426763475\n",
            "#678 Loss: 0.001587598235346377\n",
            "#679 Loss: 0.0015860018320381641\n",
            "#680 Loss: 0.001584417070262134\n",
            "#681 Loss: 0.0015828232280910015\n",
            "#682 Loss: 0.0015812384663149714\n",
            "#683 Loss: 0.0015796549851074815\n",
            "#684 Loss: 0.0015780762769281864\n",
            "#685 Loss: 0.0015764973359182477\n",
            "#686 Loss: 0.0015749182784929872\n",
            "#687 Loss: 0.0015733448090031743\n",
            "#688 Loss: 0.001571774366311729\n",
            "#689 Loss: 0.001570206950418651\n",
            "#690 Loss: 0.0015686368569731712\n",
            "#691 Loss: 0.0015670756110921502\n",
            "#692 Loss: 0.0015655123861506581\n",
            "#693 Loss: 0.0015639499761164188\n",
            "#694 Loss: 0.0015623975777998567\n",
            "#695 Loss: 0.0015608413377776742\n",
            "#696 Loss: 0.0015592895215377212\n",
            "#697 Loss: 0.0015577374724671245\n",
            "#698 Loss: 0.0015561900800094008\n",
            "#699 Loss: 0.0015546446666121483\n",
            "#700 Loss: 0.0015530996024608612\n",
            "#701 Loss: 0.001551561988890171\n",
            "#702 Loss: 0.0015500234439969063\n",
            "#703 Loss: 0.00154848862439394\n",
            "#704 Loss: 0.0015469546196982265\n",
            "#705 Loss: 0.0015454242238774896\n",
            "#706 Loss: 0.001543894992209971\n",
            "#707 Loss: 0.0015423698350787163\n",
            "#708 Loss: 0.0015408443287014961\n",
            "#709 Loss: 0.0015393226640298963\n",
            "#710 Loss: 0.0015378055395558476\n",
            "#711 Loss: 0.0015362906269729137\n",
            "#712 Loss: 0.0015347761800512671\n",
            "#713 Loss: 0.0015332623152062297\n",
            "#714 Loss: 0.0015317535726353526\n",
            "#715 Loss: 0.0015302455285564065\n",
            "#716 Loss: 0.0015287414425984025\n",
            "#717 Loss: 0.0015272392192855477\n",
            "#718 Loss: 0.0015257359482347965\n",
            "#719 Loss: 0.001524242921732366\n",
            "#720 Loss: 0.0015227453550323844\n",
            "#721 Loss: 0.0015212533762678504\n",
            "#722 Loss: 0.001519760931842029\n",
            "#723 Loss: 0.0015182732604444027\n",
            "#724 Loss: 0.0015167867531999946\n",
            "#725 Loss: 0.0015153061831369996\n",
            "#726 Loss: 0.00151382468175143\n",
            "#727 Loss: 0.0015123452758416533\n",
            "#728 Loss: 0.0015108701772987843\n",
            "#729 Loss: 0.0015093934489414096\n",
            "#730 Loss: 0.001507922657765448\n",
            "#731 Loss: 0.0015064537292346358\n",
            "#732 Loss: 0.00150498712901026\n",
            "#733 Loss: 0.0015035216929391026\n",
            "#734 Loss: 0.0015020616119727492\n",
            "#735 Loss: 0.0015006009489297867\n",
            "#736 Loss: 0.0014991434291005135\n",
            "#737 Loss: 0.0014976909151300788\n",
            "#738 Loss: 0.0014962359564378858\n",
            "#739 Loss: 0.001494788215495646\n",
            "#740 Loss: 0.0014933362836018205\n",
            "#741 Loss: 0.0014918920351192355\n",
            "#742 Loss: 0.001490452908910811\n",
            "#743 Loss: 0.0014890070306137204\n",
            "#744 Loss: 0.001487570465542376\n",
            "#745 Loss: 0.001486134366132319\n",
            "#746 Loss: 0.0014846968697384\n",
            "#747 Loss: 0.0014832663582637906\n",
            "#748 Loss: 0.0014818419003859162\n",
            "#749 Loss: 0.0014804137172177434\n",
            "#750 Loss: 0.0014789866982027888\n",
            "#751 Loss: 0.0014775656163692474\n",
            "#752 Loss: 0.0014761463971808553\n",
            "#753 Loss: 0.0014747303212061524\n",
            "#754 Loss: 0.0014733158750459552\n",
            "#755 Loss: 0.0014718972379341722\n",
            "#756 Loss: 0.0014704893110319972\n",
            "#757 Loss: 0.0014690832467749715\n",
            "#758 Loss: 0.0014676727587357163\n",
            "#759 Loss: 0.001466269139200449\n",
            "#760 Loss: 0.0014648739015683532\n",
            "#761 Loss: 0.0014634731924161315\n",
            "#762 Loss: 0.0014620762085542083\n",
            "#763 Loss: 0.0014606817858293653\n",
            "#764 Loss: 0.0014592894585803151\n",
            "#765 Loss: 0.0014578973641619086\n",
            "#766 Loss: 0.0014565136516466737\n",
            "#767 Loss: 0.0014551269123330712\n",
            "#768 Loss: 0.0014537431998178363\n",
            "#769 Loss: 0.001452364376746118\n",
            "#770 Loss: 0.0014509843895211816\n",
            "#771 Loss: 0.0014496116200461984\n",
            "#772 Loss: 0.001448236289434135\n",
            "#773 Loss: 0.0014468659646809101\n",
            "#774 Loss: 0.001445501227863133\n",
            "#775 Loss: 0.0014441300882026553\n",
            "#776 Loss: 0.0014427653513848782\n",
            "#777 Loss: 0.0014414065517485142\n",
            "#778 Loss: 0.001440047868527472\n",
            "#779 Loss: 0.0014386847615242004\n",
            "#780 Loss: 0.0014373307349160314\n",
            "#781 Loss: 0.0014359811320900917\n",
            "#782 Loss: 0.0014346283860504627\n",
            "#783 Loss: 0.0014332822756841779\n",
            "#784 Loss: 0.0014319373294711113\n",
            "#785 Loss: 0.0014305924996733665\n",
            "#786 Loss: 0.001429248950444162\n",
            "#787 Loss: 0.0014279078459367156\n",
            "#788 Loss: 0.00142657570540905\n",
            "#789 Loss: 0.0014252375112846494\n",
            "#790 Loss: 0.0014239060692489147\n",
            "#791 Loss: 0.0014225729973986745\n",
            "#792 Loss: 0.001421246794052422\n",
            "#793 Loss: 0.0014199245488271117\n",
            "#794 Loss: 0.0014186002081260085\n",
            "#795 Loss: 0.0014172802912071347\n",
            "#796 Loss: 0.0014159586280584335\n",
            "#797 Loss: 0.0014146453468129039\n",
            "#798 Loss: 0.001413327525369823\n",
            "#799 Loss: 0.001412017154507339\n",
            "#800 Loss: 0.0014107073657214642\n",
            "#801 Loss: 0.0014093982754275203\n",
            "#802 Loss: 0.001408092794008553\n",
            "#803 Loss: 0.0014067903393879533\n",
            "#804 Loss: 0.001405489630997181\n",
            "#805 Loss: 0.0014041914837434888\n",
            "#806 Loss: 0.001402895781211555\n",
            "#807 Loss: 0.0014015979832038283\n",
            "#808 Loss: 0.001400308683514595\n",
            "#809 Loss: 0.001399019849486649\n",
            "#810 Loss: 0.0013977320631965995\n",
            "#811 Loss: 0.0013964468380436301\n",
            "#812 Loss: 0.0013951631262898445\n",
            "#813 Loss: 0.0013938798801973462\n",
            "#814 Loss: 0.001392605248838663\n",
            "#815 Loss: 0.0013913282891735435\n",
            "#816 Loss: 0.0013900516787543893\n",
            "#817 Loss: 0.0013887815875932574\n",
            "#818 Loss: 0.0013875117292627692\n",
            "#819 Loss: 0.0013862410560250282\n",
            "#820 Loss: 0.0013849776005372405\n",
            "#821 Loss: 0.0013837151927873492\n",
            "#822 Loss: 0.001382452785037458\n",
            "#823 Loss: 0.0013811937533318996\n",
            "#824 Loss: 0.0013799384469166398\n",
            "#825 Loss: 0.0013786805793642998\n",
            "#826 Loss: 0.0013774315593764186\n",
            "#827 Loss: 0.0013761791633442044\n",
            "#828 Loss: 0.0013749342178925872\n",
            "#829 Loss: 0.001373683917336166\n",
            "#830 Loss: 0.0013724406016990542\n",
            "#831 Loss: 0.0013712020590901375\n",
            "#832 Loss: 0.0013699629344046116\n",
            "#833 Loss: 0.0013687253231182694\n",
            "#834 Loss: 0.0013674888759851456\n",
            "#835 Loss: 0.001366257667541504\n",
            "#836 Loss: 0.0013650240143761039\n",
            "#837 Loss: 0.0013637985102832317\n",
            "#838 Loss: 0.0013625695137307048\n",
            "#839 Loss: 0.0013613473856821656\n",
            "#840 Loss: 0.0013601245591416955\n",
            "#841 Loss: 0.0013589028967544436\n",
            "#842 Loss: 0.0013576826313510537\n",
            "#843 Loss: 0.0013564680702984333\n",
            "#844 Loss: 0.001355254091322422\n",
            "#845 Loss: 0.0013540444197133183\n",
            "#846 Loss: 0.0013528339331969619\n",
            "#847 Loss: 0.0013516262406483293\n",
            "#848 Loss: 0.0013504214584827423\n",
            "#849 Loss: 0.0013492213329300284\n",
            "#850 Loss: 0.0013480178313329816\n",
            "#851 Loss: 0.0013468186371028423\n",
            "#852 Loss: 0.0013456203741952777\n",
            "#853 Loss: 0.0013444265350699425\n",
            "#854 Loss: 0.00134323351085186\n",
            "#855 Loss: 0.0013420459581539035\n",
            "#856 Loss: 0.001340857706964016\n",
            "#857 Loss: 0.0013396674767136574\n",
            "#858 Loss: 0.001338483882136643\n",
            "#859 Loss: 0.0013373028486967087\n",
            "#860 Loss: 0.001336124143563211\n",
            "#861 Loss: 0.0013349441578611732\n",
            "#862 Loss: 0.001333769760094583\n",
            "#863 Loss: 0.0013325936160981655\n",
            "#864 Loss: 0.0013314204989001155\n",
            "#865 Loss: 0.0013302535517141223\n",
            "#866 Loss: 0.0013290876522660255\n",
            "#867 Loss: 0.0013279180275276303\n",
            "#868 Loss: 0.0013267575995996594\n",
            "#869 Loss: 0.0013255964731797576\n",
            "#870 Loss: 0.0013244355795904994\n",
            "#871 Loss: 0.0013232786441221833\n",
            "#872 Loss: 0.0013221194967627525\n",
            "#873 Loss: 0.0013209710596129298\n",
            "#874 Loss: 0.0013198158703744411\n",
            "#875 Loss: 0.001318669761531055\n",
            "#876 Loss: 0.0013175234198570251\n",
            "#877 Loss: 0.0013163769617676735\n",
            "#878 Loss: 0.0013152336468920112\n",
            "#879 Loss: 0.0013140938244760036\n",
            "#880 Loss: 0.0013129523722454906\n",
            "#881 Loss: 0.0013118124334141612\n",
            "#882 Loss: 0.0013106806436553597\n",
            "#883 Loss: 0.001309549785219133\n",
            "#884 Loss: 0.0013084136880934238\n",
            "#885 Loss: 0.0013072850415483117\n",
            "#886 Loss: 0.001306158839724958\n",
            "#887 Loss: 0.0013050338020548224\n",
            "#888 Loss: 0.0013039126060903072\n",
            "#889 Loss: 0.0013027893146499991\n",
            "#890 Loss: 0.0013016738230362535\n",
            "#891 Loss: 0.0013005557702854276\n",
            "#892 Loss: 0.0012994370190426707\n",
            "#893 Loss: 0.001298326882533729\n",
            "#894 Loss: 0.0012972120894119143\n",
            "#895 Loss: 0.001296103815548122\n",
            "#896 Loss: 0.0012949990341439843\n",
            "#897 Loss: 0.001293891342356801\n",
            "#898 Loss: 0.0012927907519042492\n",
            "#899 Loss: 0.0012916905106976628\n",
            "#900 Loss: 0.0012905864277854562\n",
            "#901 Loss: 0.0012894885148853064\n",
            "#902 Loss: 0.0012883964227512479\n",
            "#903 Loss: 0.001287300605326891\n",
            "#904 Loss: 0.001286210143007338\n",
            "#905 Loss: 0.0012851195642724633\n",
            "#906 Loss: 0.0012840339913964272\n",
            "#907 Loss: 0.0012829439947381616\n",
            "#908 Loss: 0.0012818608665838838\n",
            "#909 Loss: 0.0012807835591956973\n",
            "#910 Loss: 0.0012797001982107759\n",
            "#911 Loss: 0.001278619864024222\n",
            "#912 Loss: 0.0012775474460795522\n",
            "#913 Loss: 0.0012764683924615383\n",
            "#914 Loss: 0.0012753988848999143\n",
            "#915 Loss: 0.0012743285624310374\n",
            "#916 Loss: 0.0012732604518532753\n",
            "#917 Loss: 0.0012721909442916512\n",
            "#918 Loss: 0.0012711312156170607\n",
            "#919 Loss: 0.0012700649676844478\n",
            "#920 Loss: 0.001269005355425179\n",
            "#921 Loss: 0.0012679428327828646\n",
            "#922 Loss: 0.0012668878771364689\n",
            "#923 Loss: 0.0012658333871513605\n",
            "#924 Loss: 0.0012647812254726887\n",
            "#925 Loss: 0.0012637281324714422\n",
            "#926 Loss: 0.0012626786483451724\n",
            "#927 Loss: 0.0012616284657269716\n",
            "#928 Loss: 0.001260582241229713\n",
            "#929 Loss: 0.0012595379957929254\n",
            "#930 Loss: 0.001258495613001287\n",
            "#931 Loss: 0.001257458352483809\n",
            "#932 Loss: 0.0012564185308292508\n",
            "#933 Loss: 0.0012553847627714276\n",
            "#934 Loss: 0.0012543454067781568\n",
            "#935 Loss: 0.0012533131521195173\n",
            "#936 Loss: 0.0012522811302915215\n",
            "#937 Loss: 0.0012512515531852841\n",
            "#938 Loss: 0.0012502280296757817\n",
            "#939 Loss: 0.001249198685400188\n",
            "#940 Loss: 0.0012481767917051911\n",
            "#941 Loss: 0.001247153733856976\n",
            "#942 Loss: 0.0012461330043151975\n",
            "#943 Loss: 0.0012451136717572808\n",
            "#944 Loss: 0.0012440969003364444\n",
            "#945 Loss: 0.0012430849019438028\n",
            "#946 Loss: 0.0012420706916600466\n",
            "#947 Loss: 0.0012410605559125543\n",
            "#948 Loss: 0.0012400522828102112\n",
            "#949 Loss: 0.0012390409829095006\n",
            "#950 Loss: 0.0012380381813272834\n",
            "#951 Loss: 0.0012370330514386296\n",
            "#952 Loss: 0.0012360289692878723\n",
            "#953 Loss: 0.0012350294273346663\n",
            "#954 Loss: 0.0012340295361354947\n",
            "#955 Loss: 0.0012330316239967942\n",
            "#956 Loss: 0.001232037553563714\n",
            "#957 Loss: 0.0012310427846387029\n",
            "#958 Loss: 0.001230052555911243\n",
            "#959 Loss: 0.001229063724167645\n",
            "#960 Loss: 0.0012280764058232307\n",
            "#961 Loss: 0.001227090135216713\n",
            "#962 Loss: 0.0012261050287634134\n",
            "#963 Loss: 0.001225121901370585\n",
            "#964 Loss: 0.0012241428485140204\n",
            "#965 Loss: 0.0012231607688590884\n",
            "#966 Loss: 0.0012221833458170295\n",
            "#967 Loss: 0.0012212091824039817\n",
            "#968 Loss: 0.0012202319921925664\n",
            "#969 Loss: 0.0012192601570859551\n",
            "#970 Loss: 0.0012182925129309297\n",
            "#971 Loss: 0.0012173199793323874\n",
            "#972 Loss: 0.0012163560604676604\n",
            "#973 Loss: 0.0012153887655586004\n",
            "#974 Loss: 0.0012144240317866206\n",
            "#975 Loss: 0.0012134634889662266\n",
            "#976 Loss: 0.001212502014823258\n",
            "#977 Loss: 0.0012115431018173695\n",
            "#978 Loss: 0.0012105886125937104\n",
            "#979 Loss: 0.001209630281664431\n",
            "#980 Loss: 0.0012086780043318868\n",
            "#981 Loss: 0.0012077268911525607\n",
            "#982 Loss: 0.0012067751958966255\n",
            "#983 Loss: 0.0012058262946084142\n",
            "#984 Loss: 0.0012048814678564668\n",
            "#985 Loss: 0.0012039337307214737\n",
            "#986 Loss: 0.0012029916979372501\n",
            "#987 Loss: 0.0012020505964756012\n",
            "#988 Loss: 0.0012011100770905614\n",
            "#989 Loss: 0.0012001696741208434\n",
            "#990 Loss: 0.001199235673993826\n",
            "#991 Loss: 0.0011982994619756937\n",
            "#992 Loss: 0.0011973654618486762\n",
            "#993 Loss: 0.0011964350705966353\n",
            "#994 Loss: 0.0011955033987760544\n",
            "#995 Loss: 0.0011945762671530247\n",
            "#996 Loss: 0.0011936478549614549\n",
            "#997 Loss: 0.0011927245650440454\n",
            "#998 Loss: 0.0011917981319129467\n",
            "#999 Loss: 0.001190874958410859\n",
            "Predicted data based on trained weights: \n",
            "Input (scaled): \n",
            "tensor([0.5000, 1.0000])\n",
            "Output: \n",
            "tensor([0.9476])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type Neural_Network. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "OKrLgZ_9BimW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}